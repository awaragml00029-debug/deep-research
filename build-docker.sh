#!/bin/bash

# Deep Research Docker æ‰“åŒ…è„šæœ¬
# æ”¯æŒå¼€æºç‰ˆå’Œåˆ†å‘ç‰ˆçš„æ„å»º

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ‰“å°å¸¦é¢œè‰²çš„æ¶ˆæ¯
print_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ‰“å°æ ‡é¢˜
print_header() {
    echo ""
    echo -e "${GREEN}================================================${NC}"
    echo -e "${GREEN}$1${NC}"
    echo -e "${GREEN}================================================${NC}"
    echo ""
}

# AIä¾›åº”å•†åˆ—è¡¨å’Œé…ç½®
declare -A AI_PROVIDERS=(
    ["1"]="google|Google Gemini|GOOGLE_GENERATIVE_AI|https://generativelanguage.googleapis.com|gemini-2.5-pro|gemini-2.5-flash"
    ["2"]="google-vertex|Google Vertex AI|GOOGLE_VERTEX|https://LOCATION-aiplatform.googleapis.com|gemini-2.5-pro|gemini-2.5-flash"
    ["3"]="openrouter|OpenRouter|OPENROUTER|https://openrouter.ai/api|anthropic/claude-3.5-sonnet|anthropic/claude-3.5-haiku"
    ["4"]="openai|OpenAI|OPENAI|https://api.openai.com|gpt-5|gpt-5-mini"
    ["5"]="anthropic|Anthropic Claude|ANTHROPIC|https://api.anthropic.com|claude-3-5-sonnet-20250219|claude-3-5-haiku-20250219"
    ["6"]="deepseek|DeepSeek|DEEPSEEK|https://api.deepseek.com|deepseek-reasoner|deepseek-chat"
    ["7"]="xai|XAI (Grok)|XAI|https://api.x.ai|grok-beta|grok-beta"
    ["8"]="mistral|Mistral AI|MISTRAL|https://api.mistral.ai|mistral-large-latest|mistral-medium-latest"
    ["9"]="azure|Azure OpenAI|AZURE|https://YOUR-RESOURCE.openai.azure.com|gpt-5|gpt-5-mini"
    ["10"]="openaicompatible|OpenAI Compatible|OPENAI_COMPATIBLE|https://api.example.com|custom-model|custom-model"
    ["11"]="pollinations|Pollinations.ai (Free)|POLLINATIONS|https://text.pollinations.ai/openai|openai|openai"
    ["12"]="ollama|Ollama (Local)|OLLAMA|http://localhost:11434|llama3.1|llama3.1"
)

# æ˜¾ç¤ºAIä¾›åº”å•†é€‰æ‹©èœå•
show_provider_menu() {
    print_header "é€‰æ‹© AI ä¾›åº”å•†"
    echo "1)  Google Gemini"
    echo "2)  Google Vertex AI"
    echo "3)  OpenRouter"
    echo "4)  OpenAI"
    echo "5)  Anthropic Claude"
    echo "6)  DeepSeek"
    echo "7)  XAI (Grok)"
    echo "8)  Mistral AI"
    echo "9)  Azure OpenAI"
    echo "10) OpenAI Compatible"
    echo "11) Pollinations.ai (Free)"
    echo "12) Ollama (Local)"
    echo ""
}

# è·å–ä¾›åº”å•†ä¿¡æ¯
get_provider_info() {
    local choice=$1
    local field=$2
    local provider_info="${AI_PROVIDERS[$choice]}"

    IFS='|' read -r provider_id provider_name env_prefix default_base_url default_thinking default_networking <<< "$provider_info"

    case $field in
        "id") echo "$provider_id" ;;
        "name") echo "$provider_name" ;;
        "env") echo "$env_prefix" ;;
        "url") echo "$default_base_url" ;;
        "thinking") echo "$default_thinking" ;;
        "networking") echo "$default_networking" ;;
    esac
}

# ä¸»å‡½æ•°
main() {
    print_header "Deep Research Docker æ„å»ºè„šæœ¬"

    # æ­¥éª¤1: é€‰æ‹©ç‰ˆæœ¬ç±»å‹
    echo "è¯·é€‰æ‹©æ„å»ºç±»å‹ï¼š"
    echo "1) å¼€æºç‰ˆ (ä¿æŒæ‰€æœ‰åŠŸèƒ½ï¼Œæ— é™åˆ¶)"
    echo "2) åˆ†å‘ç‰ˆ (ç®€åŒ–é…ç½®ï¼Œåªä¿ç•™æŒ‡å®šçš„AIä¾›åº”å•†)"
    echo ""
    read -p "è¯·è¾“å…¥é€‰æ‹© [1/2]: " build_type

    case $build_type in
        1)
            build_opensource
            ;;
        2)
            build_distribution
            ;;
        *)
            print_error "æ— æ•ˆçš„é€‰æ‹©ï¼"
            exit 1
            ;;
    esac
}

# æ„å»ºå¼€æºç‰ˆ
build_opensource() {
    print_header "æ„å»ºå¼€æºç‰ˆ"

    print_info "å¼€æºç‰ˆå°†ä½¿ç”¨åŸæœ‰çš„ Dockerfile å’Œ docker-compose.yml"
    print_info "ä¿æŒæ‰€æœ‰12ä¸ªAIä¾›åº”å•†å¯é€‰"

    # è¯¢é—®é•œåƒåç§°
    read -p "è¯·è¾“å…¥é•œåƒåç§° [deep-research]: " image_name
    image_name=${image_name:-deep-research}

    read -p "è¯·è¾“å…¥é•œåƒæ ‡ç­¾ [latest]: " image_tag
    image_tag=${image_tag:-latest}

    # æ„å»ºé•œåƒ
    print_info "å¼€å§‹æ„å»º Docker é•œåƒ: ${image_name}:${image_tag}"
    docker build -t "${image_name}:${image_tag}" .

    print_success "å¼€æºç‰ˆæ„å»ºå®Œæˆï¼"
    print_info "é•œåƒåç§°: ${image_name}:${image_tag}"
    echo ""
    print_info "ä½¿ç”¨æ–¹æ³•ï¼š"
    echo "  1. å¤åˆ¶ env.tpl ä¸º .env"
    echo "  2. ç¼–è¾‘ .env æ–‡ä»¶ï¼Œé…ç½®ä½ éœ€è¦çš„AIä¾›åº”å•†"
    echo "  3. è¿è¡Œ: docker-compose up -d"
    echo ""
}

# æ„å»ºåˆ†å‘ç‰ˆ
build_distribution() {
    print_header "æ„å»ºåˆ†å‘ç‰ˆ"

    # æ­¥éª¤1: é€‰æ‹©AIä¾›åº”å•†
    show_provider_menu
    read -p "è¯·é€‰æ‹©AIä¾›åº”å•† [1-12]: " provider_choice

    if [[ ! "$provider_choice" =~ ^[0-9]+$ ]] || [ "$provider_choice" -lt 1 ] || [ "$provider_choice" -gt 12 ]; then
        print_error "æ— æ•ˆçš„é€‰æ‹©ï¼"
        exit 1
    fi

    PROVIDER_ID=$(get_provider_info "$provider_choice" "id")
    PROVIDER_NAME=$(get_provider_info "$provider_choice" "name")
    ENV_PREFIX=$(get_provider_info "$provider_choice" "env")
    DEFAULT_BASE_URL=$(get_provider_info "$provider_choice" "url")
    DEFAULT_THINKING=$(get_provider_info "$provider_choice" "thinking")
    DEFAULT_NETWORKING=$(get_provider_info "$provider_choice" "networking")

    print_success "å·²é€‰æ‹©: $PROVIDER_NAME"

    # æ­¥éª¤2: é€‰æ‹©æ¨¡å¼
    echo ""
    print_header "é€‰æ‹©è¿è¡Œæ¨¡å¼"
    echo "1) Local æ¨¡å¼ - æµè§ˆå™¨ç›´æ¥è°ƒç”¨AI API (ç”¨æˆ·éœ€è¾“å…¥API Key)"
    echo "2) Proxy æ¨¡å¼ - æœåŠ¡ç«¯ä»£ç†è°ƒç”¨ (API Keyé¢„è®¾åœ¨æœåŠ¡ç«¯ï¼Œç”¨æˆ·åªéœ€å¯†ç )"
    echo ""
    read -p "è¯·é€‰æ‹©æ¨¡å¼ [1/2]: " mode_choice

    case $mode_choice in
        1)
            MODE="local"
            print_success "å·²é€‰æ‹©: Local æ¨¡å¼"
            ;;
        2)
            MODE="proxy"
            print_success "å·²é€‰æ‹©: Proxy æ¨¡å¼"
            ;;
        *)
            print_error "æ— æ•ˆçš„é€‰æ‹©ï¼"
            exit 1
            ;;
    esac

    # æ­¥éª¤3: é…ç½®API Base URLï¼ˆä»…Localæ¨¡å¼éœ€è¦ï¼‰
    if [ "$MODE" = "local" ]; then
        echo ""
        print_info "Localæ¨¡å¼éœ€è¦é…ç½®API Base URLï¼ˆå‰ç«¯ç›´æ¥è°ƒç”¨ï¼‰"
        read -p "API Base URL [${DEFAULT_BASE_URL}]: " api_base_url
        api_base_url=${api_base_url:-$DEFAULT_BASE_URL}
    else
        # Proxyæ¨¡å¼ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®ï¼Œæœ‰é»˜è®¤å€¼
        api_base_url="$DEFAULT_BASE_URL"
    fi

    # æ­¥éª¤4: é…ç½®æ¨¡å‹
    echo ""
    print_header "é…ç½®æ¨¡å‹"
    print_info "Thinking Model: ç”¨äºæ·±åº¦æ€è€ƒçš„ä¸»è¦æ¨¡å‹"
    read -p "Thinking Model [${DEFAULT_THINKING}]: " thinking_model
    thinking_model=${thinking_model:-$DEFAULT_THINKING}

    print_info "Task Model: ç”¨äºå¿«é€Ÿä»»åŠ¡çš„è¾…åŠ©æ¨¡å‹"
    read -p "Task Model [${DEFAULT_NETWORKING}]: " networking_model
    networking_model=${networking_model:-$DEFAULT_NETWORKING}

    # æ­¥éª¤6: é…ç½®é•œåƒåç§°
    echo ""
    read -p "è¯·è¾“å…¥é•œåƒåç§° [deep-research-dist]: " image_name
    image_name=${image_name:-deep-research-dist}

    read -p "è¯·è¾“å…¥é•œåƒæ ‡ç­¾ [latest]: " image_tag
    image_tag=${image_tag:-latest}

    # ç”Ÿæˆç¦ç”¨åˆ—è¡¨ï¼ˆç¦ç”¨é™¤é€‰ä¸­å¤–çš„æ‰€æœ‰ä¾›åº”å•†ï¼‰
    DISABLED_PROVIDERS=""
    for key in "${!AI_PROVIDERS[@]}"; do
        current_id=$(get_provider_info "$key" "id")
        if [ "$current_id" != "$PROVIDER_ID" ]; then
            if [ -z "$DISABLED_PROVIDERS" ]; then
                DISABLED_PROVIDERS="$current_id"
            else
                DISABLED_PROVIDERS="${DISABLED_PROVIDERS},$current_id"
            fi
        fi
    done

    # æ˜¾ç¤ºé…ç½®æ‘˜è¦
    print_header "é…ç½®æ‘˜è¦"
    echo "AI ä¾›åº”å•†: $PROVIDER_NAME ($PROVIDER_ID)"
    echo "è¿è¡Œæ¨¡å¼: $MODE"
    if [ "$MODE" = "local" ]; then
        echo "API Base URL: $api_base_url"
    else
        echo "API Base URL: (è¿è¡Œæ—¶é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®)"
    fi
    echo "Thinking Model: $thinking_model"
    echo "Task Model: $networking_model"
    echo "é•œåƒåç§°: ${image_name}:${image_tag}"
    echo ""

    read -p "ç¡®è®¤ä»¥ä¸Šé…ç½®å¹¶å¼€å§‹æ„å»ºï¼Ÿ[y/N]: " confirm
    if [[ ! "$confirm" =~ ^[Yy]$ ]]; then
        print_warning "å·²å–æ¶ˆæ„å»º"
        exit 0
    fi

    # ç”Ÿæˆåˆ†å‘ç‰ˆæ–‡ä»¶
    generate_dist_files

    # æ„å»ºé•œåƒ
    print_info "å¼€å§‹æ„å»ºåˆ†å‘ç‰ˆ Docker é•œåƒ..."
    docker build -f Dockerfile.dist -t "${image_name}:${image_tag}" \
        --build-arg DISABLED_PROVIDERS="$DISABLED_PROVIDERS" \
        --build-arg DEFAULT_PROVIDER="$PROVIDER_ID" \
        --build-arg DEFAULT_MODE="$MODE" \
        --build-arg API_BASE_URL="$api_base_url" \
        --build-arg THINKING_MODEL="$thinking_model" \
        --build-arg NETWORKING_MODEL="$networking_model" \
        --build-arg DIST_MODE="$MODE" \
        .

    print_success "åˆ†å‘ç‰ˆæ„å»ºå®Œæˆï¼"
    print_info "é•œåƒåç§°: ${image_name}:${image_tag}"

    # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
    show_usage_instructions
}

# ç”Ÿæˆåˆ†å‘ç‰ˆæ–‡ä»¶
generate_dist_files() {
    print_info "ç”Ÿæˆåˆ†å‘ç‰ˆé…ç½®æ–‡ä»¶..."

    # ç”Ÿæˆæºç patchè„šæœ¬
    cat > patch-dist.sh << 'PATCHEOF'
#!/bin/sh
# åˆ†å‘ç‰ˆæºç patchè„šæœ¬ - è®¾ç½®é»˜è®¤å€¼

PROVIDER_ID="$1"
API_BASE_URL="$2"
THINKING_MODEL="$3"
NETWORKING_MODEL="$4"

SETTING_FILE="src/store/setting.ts"

echo "æ­£åœ¨ä¸ºåˆ†å‘ç‰ˆè®¾ç½®é»˜è®¤å€¼..."
echo "Provider: $PROVIDER_ID"
echo "API Base URL: $API_BASE_URL"
echo "Thinking Model: $THINKING_MODEL"
echo "Networking Model: $NETWORKING_MODEL"

# æ ¹æ®ä¸åŒçš„providerè®¾ç½®å¯¹åº”çš„å­—æ®µå
case "$PROVIDER_ID" in
    "google")
        API_KEY_FIELD="apiKey"
        API_PROXY_FIELD="apiProxy"
        THINKING_FIELD="thinkingModel"
        NETWORKING_FIELD="networkingModel"
        ;;
    "google-vertex")
        API_KEY_FIELD="googleVertexProject"
        API_PROXY_FIELD="googleVertexLocation"
        THINKING_FIELD="googleVertexThinkingModel"
        NETWORKING_FIELD="googleVertexNetworkingModel"
        ;;
    "openrouter")
        API_KEY_FIELD="openRouterApiKey"
        API_PROXY_FIELD="openRouterApiProxy"
        THINKING_FIELD="openRouterThinkingModel"
        NETWORKING_FIELD="openRouterNetworkingModel"
        ;;
    "openai")
        API_KEY_FIELD="openAIApiKey"
        API_PROXY_FIELD="openAIApiProxy"
        THINKING_FIELD="openAIThinkingModel"
        NETWORKING_FIELD="openAINetworkingModel"
        ;;
    "anthropic")
        API_KEY_FIELD="anthropicApiKey"
        API_PROXY_FIELD="anthropicApiProxy"
        THINKING_FIELD="anthropicThinkingModel"
        NETWORKING_FIELD="anthropicNetworkingModel"
        ;;
    "deepseek")
        API_KEY_FIELD="deepseekApiKey"
        API_PROXY_FIELD="deepseekApiProxy"
        THINKING_FIELD="deepseekThinkingModel"
        NETWORKING_FIELD="deepseekNetworkingModel"
        ;;
    "xai")
        API_KEY_FIELD="xAIApiKey"
        API_PROXY_FIELD="xAIApiProxy"
        THINKING_FIELD="xAIThinkingModel"
        NETWORKING_FIELD="xAINetworkingModel"
        ;;
    "mistral")
        API_KEY_FIELD="mistralApiKey"
        API_PROXY_FIELD="mistralApiProxy"
        THINKING_FIELD="mistralThinkingModel"
        NETWORKING_FIELD="mistralNetworkingModel"
        ;;
    "azure")
        API_KEY_FIELD="azureApiKey"
        API_PROXY_FIELD="azureResourceName"
        THINKING_FIELD="azureThinkingModel"
        NETWORKING_FIELD="azureNetworkingModel"
        ;;
    "openaicompatible")
        API_KEY_FIELD="openAICompatibleApiKey"
        API_PROXY_FIELD="openAICompatibleApiProxy"
        THINKING_FIELD="openAICompatibleThinkingModel"
        NETWORKING_FIELD="openAICompatibleNetworkingModel"
        ;;
    "pollinations")
        API_KEY_FIELD="pollinationsApiProxy"
        API_PROXY_FIELD="pollinationsApiProxy"
        THINKING_FIELD="pollinationsThinkingModel"
        NETWORKING_FIELD="pollinationsNetworkingModel"
        ;;
    "ollama")
        API_KEY_FIELD="ollamaApiProxy"
        API_PROXY_FIELD="ollamaApiProxy"
        THINKING_FIELD="ollamaThinkingModel"
        NETWORKING_FIELD="ollamaNetworkingModel"
        ;;
esac

# ä¿®æ”¹é»˜è®¤provider
sed -i "s/provider: \"google\",/provider: \"$PROVIDER_ID\",/" "$SETTING_FILE"

# ä¿®æ”¹API Proxyé»˜è®¤å€¼
sed -i "s|$API_PROXY_FIELD: \"\",|$API_PROXY_FIELD: \"$API_BASE_URL\",|" "$SETTING_FILE"

# ä¿®æ”¹æ¨¡å‹é»˜è®¤å€¼
sed -i "s|$THINKING_FIELD: \"[^\"]*\",|$THINKING_FIELD: \"$THINKING_MODEL\",|" "$SETTING_FILE"
sed -i "s|$NETWORKING_FIELD: \"[^\"]*\",|$NETWORKING_FIELD: \"$NETWORKING_MODEL\",|" "$SETTING_FILE"

# ä¹Ÿä¿®æ”¹å…¨å±€çš„é»˜è®¤æ¨¡å‹
sed -i "s|thinkingModel: \"[^\"]*\",|thinkingModel: \"$THINKING_MODEL\",|" "$SETTING_FILE"
sed -i "s|networkingModel: \"[^\"]*\",|networkingModel: \"$NETWORKING_MODEL\",|" "$SETTING_FILE"

echo "é»˜è®¤å€¼è®¾ç½®å®Œæˆ"
PATCHEOF

    chmod +x patch-dist.sh

    # ç”Ÿæˆ Dockerfile.dist
    cat > Dockerfile.dist << 'EOF'
FROM node:18-alpine AS base

# Install dependencies only when needed
FROM base AS deps
RUN apk add --no-cache libc6-compat

WORKDIR /app

# Install dependencies based on the preferred package manager
COPY package.json pnpm-lock.yaml ./
RUN yarn global add pnpm && pnpm install --frozen-lockfile

# Rebuild the source code only when needed
FROM base AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY . .

# æ„å»ºå‚æ•°
ARG DISABLED_PROVIDERS
ARG DEFAULT_PROVIDER
ARG DEFAULT_MODE
ARG API_BASE_URL
ARG THINKING_MODEL
ARG NETWORKING_MODEL
ARG DIST_MODE

# åº”ç”¨åˆ†å‘ç‰ˆpatchï¼ˆä¿®æ”¹é»˜è®¤å€¼ï¼‰
COPY patch-dist.sh ./
RUN chmod +x patch-dist.sh && \
    ./patch-dist.sh "$DEFAULT_PROVIDER" "$API_BASE_URL" "$THINKING_MODEL" "$NETWORKING_MODEL"

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆæ„å»ºæ—¶æ³¨å…¥ï¼‰
ENV NEXT_PUBLIC_DISABLED_AI_PROVIDER=$DISABLED_PROVIDERS
ENV NEXT_PUBLIC_DIST_MODE=$DIST_MODE

RUN yarn run build:standalone

# Production image, copy all the files and run next
FROM base AS runner
WORKDIR /app

ENV NODE_ENV=production
ENV NEXT_PUBLIC_BUILD_MODE=standalone

# å¤åˆ¶æ„å»ºå‚æ•°åˆ°è¿è¡Œæ—¶
ARG DISABLED_PROVIDERS
ARG DEFAULT_PROVIDER
ARG DEFAULT_MODE
ARG API_BASE_URL
ARG THINKING_MODEL
ARG NETWORKING_MODEL
ARG DIST_MODE

ENV NEXT_PUBLIC_DISABLED_AI_PROVIDER=$DISABLED_PROVIDERS
ENV NEXT_PUBLIC_DEFAULT_PROVIDER=$DEFAULT_PROVIDER
ENV NEXT_PUBLIC_DEFAULT_MODE=$DEFAULT_MODE
ENV NEXT_PUBLIC_DEFAULT_API_BASE_URL=$API_BASE_URL
ENV NEXT_PUBLIC_DEFAULT_THINKING_MODEL=$THINKING_MODEL
ENV NEXT_PUBLIC_DEFAULT_NETWORKING_MODEL=$NETWORKING_MODEL
ENV NEXT_PUBLIC_DIST_MODE=$DIST_MODE

# Automatically leverage output traces to reduce image size
COPY --from=builder /app/.next/standalone ./
COPY --from=builder /app/.next/static ./.next/static
COPY --from=builder /app/public ./public

EXPOSE 3000

CMD ["node", "server.js"]
EOF

    # ç”Ÿæˆ docker-compose.dist.ymlï¼ˆä½¿ç”¨ environment é…ç½®ï¼Œä¸€ä¸ªæ–‡ä»¶æå®šï¼‰
    if [ "$MODE" = "proxy" ]; then
        cat > docker-compose.dist.yml << EOF
version: "3.9"
services:
  deep-research:
    build:
      context: .
      dockerfile: Dockerfile.dist
      args:
        DISABLED_PROVIDERS: "$DISABLED_PROVIDERS"
        DEFAULT_PROVIDER: "$PROVIDER_ID"
        DEFAULT_MODE: "$MODE"
        API_BASE_URL: "$api_base_url"
        THINKING_MODEL: "$thinking_model"
        NETWORKING_MODEL: "$networking_model"
        DIST_MODE: "$MODE"
    image: ${image_name}:${image_tag}
    container_name: deep-research-dist
    ports:
      - "3333:3000"
    restart: unless-stopped
    environment:
      # ========== Proxy æ¨¡å¼é…ç½® ==========
      # è®¿é—®å¯†ç ï¼ˆå¿…å¡«ï¼‰- æœ€ç»ˆç”¨æˆ·éœ€è¦è¾“å…¥æ­¤å¯†ç 
      - ACCESS_PASSWORD=your-password-here
      # ${PROVIDER_NAME} API Keyï¼ˆå¿…å¡«ï¼‰
      - ${ENV_PREFIX}_API_KEY=your-api-key-here
      # API Base URLï¼ˆå¯é€‰ï¼Œæœ‰é»˜è®¤å€¼ï¼‰
      # - ${ENV_PREFIX}_API_BASE_URL=https://your-custom-url
      # MCP é…ç½®
      - MCP_AI_PROVIDER=${PROVIDER_ID}
      - MCP_THINKING_MODEL=${thinking_model}
      - MCP_TASK_MODEL=${networking_model}
EOF
    else
        cat > docker-compose.dist.yml << EOF
version: "3.9"
services:
  deep-research:
    build:
      context: .
      dockerfile: Dockerfile.dist
      args:
        DISABLED_PROVIDERS: "$DISABLED_PROVIDERS"
        DEFAULT_PROVIDER: "$PROVIDER_ID"
        DEFAULT_MODE: "$MODE"
        API_BASE_URL: "$api_base_url"
        THINKING_MODEL: "$thinking_model"
        NETWORKING_MODEL: "$networking_model"
        DIST_MODE: "$MODE"
    image: ${image_name}:${image_tag}
    container_name: deep-research-dist
    ports:
      - "3333:3000"
    restart: unless-stopped
    environment:
      # ========== Local æ¨¡å¼é…ç½® ==========
      # è®¿é—®å¯†ç ï¼ˆå¯é€‰ï¼‰
      - ACCESS_PASSWORD=
      # ç”¨æˆ·åœ¨æµè§ˆå™¨ç•Œé¢è¾“å…¥ API Key å³å¯ä½¿ç”¨
EOF
    fi

    print_success "é…ç½®æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼š"
    echo "  - Dockerfile.dist"
    echo "  - docker-compose.dist.yml"
    echo "  - patch-dist.sh"
}

# æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
show_usage_instructions() {
    echo ""
    print_header "ä½¿ç”¨è¯´æ˜"

    if [ "$MODE" = "proxy" ]; then
        echo "ğŸ“¦ Proxy æ¨¡å¼ - æœåŠ¡ç«¯ä»£ç†"
        echo ""
        echo "1. ç¼–è¾‘ docker-compose.dist.ymlï¼Œé…ç½® environment éƒ¨åˆ†ï¼š"
        echo "   ${YELLOW}ACCESS_PASSWORD=your-secure-password${NC}  ï¼ˆæœ€ç»ˆç”¨æˆ·éœ€è¦è¾“å…¥çš„å¯†ç ï¼‰"
        echo "   ${YELLOW}${ENV_PREFIX}_API_KEY=your-api-key${NC}  ï¼ˆä½ çš„ ${PROVIDER_NAME} API Keyï¼‰"
        echo ""
        echo "2. å¯åŠ¨æœåŠ¡ï¼š"
        echo "   ${BLUE}docker-compose -f docker-compose.dist.yml up -d${NC}"
        echo ""
        echo "3. è®¿é—® http://localhost:3333"
        echo ""
        echo "4. æœ€ç»ˆç”¨æˆ·åªéœ€è¦è¾“å…¥è®¿é—®å¯†ç å³å¯ä½¿ç”¨"
        echo "   ${GREEN}API Key å·²åœ¨æœåŠ¡ç«¯é…ç½®ï¼Œç”¨æˆ·æ— éœ€çŸ¥é“${NC}"
    else
        echo "ğŸŒ Local æ¨¡å¼ - æµè§ˆå™¨ç›´æ¥è°ƒç”¨"
        echo ""
        echo "1. å¯åŠ¨æœåŠ¡ï¼š"
        echo "   ${BLUE}docker-compose -f docker-compose.dist.yml up -d${NC}"
        echo ""
        echo "2. è®¿é—® http://localhost:3333"
        echo ""
        echo "3. ç”¨æˆ·éœ€è¦åœ¨ç•Œé¢è¾“å…¥ï¼š"
        echo "   - API Key (å¿…å¡«)"
        echo "   ${GREEN}API Base URL å·²é¢„è®¾ä¸º: ${api_base_url}${NC}"
        echo "   ${GREEN}æ¨¡å‹å·²é¢„è®¾: Thinking=${thinking_model}, Task=${networking_model}${NC}"
    fi

    echo ""
    echo "âœ¨ ç‰¹æ€§ï¼š"
    echo "  - åªæ˜¾ç¤º ${PROVIDER_NAME} é€‰é¡¹ï¼Œå…¶ä»–ä¾›åº”å•†å·²éšè—"
    echo "  - æ¨¡å‹é…ç½®å·²å›ºå®šï¼Œç”¨æˆ·æ— éœ€é€‰æ‹©"
    echo "  - ç®€åŒ–çš„é…ç½®æµç¨‹"
    echo ""
}

# æ‰§è¡Œä¸»å‡½æ•°
main
